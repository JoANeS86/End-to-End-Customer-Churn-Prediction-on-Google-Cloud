## End-to-End Customer Churn Prediction on Google Cloud

### 1Ô∏è‚É£ Project Objective

Build an end-to-end analytics and machine learning solution on **Google Cloud Platform** to predict customer churn and provide actionable business insights.

---

### 2Ô∏è‚É£ Business Framework (PACE)

### **Plan**

Customer churn reduces recurring revenue. The goal is to identify customers at high risk of churn and understand the main drivers behind churn behavior.

### **Analysis Plan**

* Explore customer demographics, services, and billing data
* Identify churn patterns and drivers
* Engineer predictive features
* Train and evaluate ML models
* Communicate insights through dashboards

### **Construct**

* Data warehouse in **BigQuery**
* SQL-based data transformations and feature engineering
* Python-based EDA and modeling
* ML training using **Vertex AI**
* Visualization with **Looker Studio**

### **Execute**

* Deliver churn predictions
* Summarize business insights
* Recommend retention strategies

---

### 3Ô∏è‚É£ Tech Stack

* **Google Cloud Storage** ‚Äì Raw data storage
* **BigQuery** ‚Äì Data warehouse & feature engineering
* **Python** ‚Äì EDA, ML logic, evaluation
* **Vertex AI** ‚Äì Model training & experimentation
* **Looker Studio** ‚Äì Business dashboard
* **GitHub** ‚Äì Code, documentation, version control

---

### 4Ô∏è‚É£ Data Architecture

### **Cloud Storage**

* `gs://churn-project-raw/telco_churn.csv`

### **BigQuery Datasets**

* `churn_raw`
* `churn_staging`
* `churn_analytics`

### **BigQuery Tables**

1. **`churn_raw.telco_customers`**

   * Raw ingested data (no transformations)

2. **`churn_staging.customers_clean`**

   * Cleaned and standardized data
   * Type casting and null handling

3. **`churn_analytics.customer_features`**

   * One row per customer
   * ML-ready features
   * Target variable (`churn`)

---

### 5Ô∏è‚É£ SQL Tasks (BigQuery)

* Create datasets and tables
* Load raw CSV from Cloud Storage (raw data was ingested into BigQuery using direct file upload due to project billing constraints.)
* Clean and standardize data
* Encode categorical variables
* Create derived features (tenure buckets, service counts, ratios)
* Build final feature table for ML

---

### 6Ô∏è‚É£ Exploratory Data Analysis (Python)

Conducted EDA on BigQuery-hosted analytical tables using Python (Pandas, Matplotlib) in Jupyter.

* Churn rate overview
* Feature distributions
* Churn by customer segment
* Correlation analysis
* Data leakage checks

---

### 7Ô∏è‚É£ Feature Engineering

* Binary encoding (Yes/No)
* Aggregated service usage
* Contract type indicators
* Tenure-based features
* Billing behavior ratios

---

### 8Ô∏è‚É£ Machine Learning

### **Models**

* Logistic Regression (baseline & explainability)
* Tree-based model (AutoML Tables or XGBoost)

### **Evaluation Metrics**

* ROC-AUC
* Precision / Recall
* Confusion Matrix

### **Platform**

* Local Python + **Vertex AI** (safe, limited usage)

---

### 9Ô∏è‚É£ Visualization & Reporting

### **Dashboard (Looker Studio)**

* Overall churn rate
* Churn trends by contract and service
* High-risk customer segments
* Key churn drivers

### **Business Recommendations**

* Targeted retention strategies
* Suggested actions per customer segment

---

### üîü Project Deliverables

* BigQuery SQL scripts
* Python notebooks/scripts
* Vertex AI training configuration
* Looker Studio dashboard
* GitHub repository with README
* Clear business insights and conclusions

---

## üóìÔ∏è Estimated Timeline

* **Week 1** ‚Äì GCP setup & BigQuery warehouse
* **Week 2** ‚Äì SQL transformations & EDA
* **Week 3** ‚Äì Feature engineering & baseline ML
* **Week 4** ‚Äì Advanced model & evaluation
* **Week 5** ‚Äì Dashboard & insights
* **Week 6** ‚Äì Vertex AI polish & documentation
